{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df50b9a4",
   "metadata": {},
   "source": [
    "# Early vs Late Fusion\n",
    "Using the model that proved to work best, we will try to implement and compare which approach works better, early fusion or late fusion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b1f9ae",
   "metadata": {},
   "source": [
    "### Early fusion\n",
    "Early fusion combines multiple input modalities or feature sets before feeding them into the model. This typically involves concatenating raw features from different sources into a single feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52bb8811",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mDATASET\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clean_df\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Synthesis-Project-I/DATASET.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Import necessary libraries\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPreparing_Data\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functions\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# PATHS TO THE CSV FILES -----------------------------------------------------------------\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/__init__.py:22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _hard_dependencies, _dependency, _missing_dependencies\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# numpy compat\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_numpy_dev \u001b[38;5;28;01mas\u001b[39;00m _is_numpy_dev  \u001b[38;5;66;03m# pyright: ignore # noqa:F401\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hashtable \u001b[38;5;28;01mas\u001b[39;00m _hashtable, lib \u001b[38;5;28;01mas\u001b[39;00m _lib, tslib \u001b[38;5;28;01mas\u001b[39;00m _tslib\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/compat/__init__.py:18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_typing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m F\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     19\u001b[0m     is_numpy_dev,\n\u001b[1;32m     20\u001b[0m     np_version_under1p21,\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyarrow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     23\u001b[0m     pa_version_under1p01,\n\u001b[1;32m     24\u001b[0m     pa_version_under2p0,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     pa_version_under9p0,\n\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/compat/numpy/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\" support numpy compatibility across versions \"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Version\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# numpy versioning\u001b[39;00m\n\u001b[1;32m      7\u001b[0m _np_version \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39m__version__\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/util/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# pyright: reportUnusedImport = false\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_decorators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     Appender,\n\u001b[1;32m      4\u001b[0m     Substitution,\n\u001b[1;32m      5\u001b[0m     cache_readonly,\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhashing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     hash_array,\n\u001b[1;32m     10\u001b[0m     hash_pandas_object,\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(name):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/util/_decorators.py:14\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      7\u001b[0m     Any,\n\u001b[1;32m      8\u001b[0m     Callable,\n\u001b[1;32m      9\u001b[0m     Mapping,\n\u001b[1;32m     10\u001b[0m     cast,\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproperties\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cache_readonly\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_typing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     16\u001b[0m     F,\n\u001b[1;32m     17\u001b[0m     T,\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_exceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m find_stack_level\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/__init__.py:13\u001b[0m\n\u001b[1;32m      1\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaT\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaTType\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterval\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m ]\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     15\u001b[0m     NaT,\n\u001b[1;32m     16\u001b[0m     NaTType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     iNaT,\n\u001b[1;32m     22\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/interval.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.interval\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "from DATASET import clean_df\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load dataset\n",
    "df = clean_df.copy()\n",
    "df = df.dropna(subset=['nota_assignatura'])\n",
    "# Separate current year data (to predict)\n",
    "df_train = df[df['curs_academic'] != '2023/24'].copy()\n",
    "df_pred_target = df[df['curs_academic'] == '2023/24'].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92b9ca1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns=['nota_assignatura'])\n",
    "y_train = df_train['nota_assignatura']\n",
    "\n",
    "X_pred = df_pred_target.drop(columns=['nota_assignatura'])\n",
    "y_pred = df_pred_target['nota_assignatura'] \n",
    "\n",
    "# 4. Select categorical columns to encode\n",
    "categorical_cols = X_train.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ],\n",
    "    remainder='passthrough'  # Keep non-categorical columns\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "935dd0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.ensemble import VotingRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define ensemble with reduced complexity for speed\n",
    "ensemble_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', VotingRegressor(estimators=[\n",
    "        ('rf', RandomForestRegressor(n_estimators=30, max_depth=10, random_state=42)),\n",
    "        ('gb', GradientBoostingRegressor(n_estimators=50, random_state=42)),\n",
    "        ('dt', DecisionTreeRegressor(max_depth=8, random_state=42))\n",
    "    ]))\n",
    "])\n",
    "\n",
    "# Fit ensemble\n",
    "ensemble_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on 2023/24\n",
    "df_pred_target['predicted_nota_assignatura_ensemble'] = ensemble_pipeline.predict(X_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf0cbd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We assume we select the best features, in this case we included all of the features we have\n",
    "best_features = ['assignatura', 'codi_assignatura', 'curs_academic', 'discapacitat', \n",
    "                 'estudis_mare', 'estudis_pare', 'nota_d_acces', 'sexe', 'taxa_exit', 'via_acces_estudi']\n",
    "\n",
    "# Divide df_train into X and y\n",
    "X = df_train[best_features]\n",
    "y = df_train['nota_assignatura']\n",
    "\n",
    "# Split train/val to validate performance before predicting 2023/24\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c890c82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Fusion - R²: 0.4742565397311099\n",
      "Early Fusion - RMSE: 5.392016780491727\n"
     ]
    }
   ],
   "source": [
    "\n",
    "categorical_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "ensemble_early = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', VotingRegressor([\n",
    "        ('rf', RandomForestRegressor(n_estimators=30, max_depth=10, random_state=42)),\n",
    "        ('gb', GradientBoostingRegressor(n_estimators=50, random_state=42)),\n",
    "        ('dt', DecisionTreeRegressor(max_depth=8, random_state=42))\n",
    "    ]))\n",
    "])\n",
    "\n",
    "ensemble_early.fit(X_train, y_train)\n",
    "y_pred_early = ensemble_early.predict(X_val)\n",
    "\n",
    "print(\"Early Fusion - R²:\", r2_score(y_val, y_pred_early))\n",
    "print(\"Early Fusion - RMSE:\", mean_squared_error(y_val, y_pred_early))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf572beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define grupos (puedes ajustar estos grupos)\n",
    "group1 = ['assignatura', 'codi_assignatura', 'curs_academic']\n",
    "group2 = ['discapacitat', 'estudis_mare', 'estudis_pare']\n",
    "group3 = ['nota_d_acces', 'sexe', 'taxa_exit', 'via_acces_estudi']\n",
    "\n",
    "feature_groups = [group1, group2, group3]\n",
    "\n",
    "models = []\n",
    "preds_test = []\n",
    "\n",
    "for group in feature_groups:\n",
    "    X_train_g = X_train[group]\n",
    "    X_test_g = X_val[group]\n",
    "    \n",
    "    cat_cols_g = X_train_g.select_dtypes(include='object').columns.tolist()\n",
    "    preprocessor_g = ColumnTransformer([\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols_g)\n",
    "    ], remainder='passthrough')\n",
    "    \n",
    "    model_g = Pipeline([\n",
    "        ('preprocessor', preprocessor_g),\n",
    "        ('regressor', VotingRegressor([\n",
    "            ('rf', RandomForestRegressor(n_estimators=30, max_depth=10, random_state=42)),\n",
    "            ('gb', GradientBoostingRegressor(n_estimators=50, random_state=42)),\n",
    "            ('dt', DecisionTreeRegressor(max_depth=8, random_state=42))\n",
    "        ]))\n",
    "    ])\n",
    "    \n",
    "    model_g.fit(X_train_g, y_train)\n",
    "    models.append(model_g)\n",
    "    \n",
    "    pred_g = model_g.predict(X_test_g)\n",
    "    preds_test.append(pred_g)\n",
    "\n",
    "# Combina predicciones por promedio simple\n",
    "y_pred_late = np.mean(preds_test, axis=0)\n",
    "\n",
    "print(\"Late Fusion - R²:\", r2_score(y_val, y_pred_late))\n",
    "print(\"Late Fusion - RMSE:\", mean_squared_error(y_val, y_pred_late))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29001d17",
   "metadata": {},
   "source": [
    "### Late Fusion\n",
    "Late fusion involves training separate models for each modality and then combining their outputs (e.g., predictions, probabilities) afterward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a139740b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Late Fusion - R²: 0.6952073694551999\n",
      "Late Fusion - RMSE: 3.127768594326613\n"
     ]
    }
   ],
   "source": [
    "# Datos académicos\n",
    "X_academic = df_train[['assignatura', 'codi_assignatura', 'curs_academic', 'nota_d_acces', 'taxa_exit', 'via_acces_estudi']]\n",
    "\n",
    "# Datos sociodemográficos\n",
    "X_social = df_train[['discapacitat', 'estudis_mare', 'estudis_pare', 'sexe']]\n",
    "#Define grupos (puedes ajustar estos grupos)\n",
    "group1 = ['assignatura', 'codi_assignatura', 'curs_academic']\n",
    "group2 = ['discapacitat', 'estudis_mare', 'estudis_pare']\n",
    "group3 = [ 'sexe', 'taxa_exit' ]\n",
    "group4 = ['nota_d_acces',  'via_acces_estudi']  \n",
    "\n",
    "feature_groups = [group1, group2, group3, group4]\n",
    "\n",
    "models = []\n",
    "preds_test = []\n",
    "\n",
    "for group in feature_groups:\n",
    "    X_train_g = X_train[group]\n",
    "    X_test_g = X_val[group]\n",
    "    \n",
    "    cat_cols_g = X_train_g.select_dtypes(include='object').columns.tolist()\n",
    "    preprocessor_g = ColumnTransformer([\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols_g)\n",
    "    ], remainder='passthrough')\n",
    "    \n",
    "    model_g = Pipeline([\n",
    "        ('preprocessor', preprocessor_g),\n",
    "        ('regressor', VotingRegressor([\n",
    "            ('rf', RandomForestRegressor(n_estimators=30, max_depth=10, random_state=42)),\n",
    "            ('gb', GradientBoostingRegressor(n_estimators=50, random_state=42)),\n",
    "            ('dt', DecisionTreeRegressor(max_depth=8, random_state=42))\n",
    "        ]))\n",
    "    ])\n",
    "    \n",
    "    model_g.fit(X_train_g, y_train)\n",
    "    models.append(model_g)\n",
    "    \n",
    "    pred_g = model_g.predict(X_test_g)\n",
    "    preds_test.append(pred_g)\n",
    "\n",
    "# Combina predicciones por promedio simple\n",
    "y_pred_late = np.mean(preds_test, axis=0)\n",
    "\n",
    "print(\"Late Fusion - R²:\", r2_score(y_val, y_pred_late))\n",
    "print(\"Late Fusion - RMSE:\", mean_squared_error(y_val, y_pred_late))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbb310b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Late Fusion - R²: 0.22040590859271847\n",
      "Late Fusion - RMSE: 7.995504919243982\n"
     ]
    }
   ],
   "source": [
    "#Define grupos (puedes ajustar estos grupos)\n",
    "group1 = ['assignatura', 'codi_assignatura', 'curs_academic']\n",
    "group2 = ['discapacitat', 'estudis_mare', 'estudis_pare']\n",
    "group3 = [ 'sexe', 'taxa_exit' ]\n",
    "group4 = ['nota_d_acces',  'via_acces_estudi']  \n",
    "\n",
    "feature_groups = [group1, group2, group3, group4]\n",
    "\n",
    "models = []\n",
    "preds_test = []\n",
    "\n",
    "for group in feature_groups:\n",
    "    X_train_g = X_train[group]\n",
    "    X_test_g = X_val[group]\n",
    "    \n",
    "    cat_cols_g = X_train_g.select_dtypes(include='object').columns.tolist()\n",
    "    preprocessor_g = ColumnTransformer([\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols_g)\n",
    "    ], remainder='passthrough')\n",
    "    \n",
    "    model_g = Pipeline([\n",
    "        ('preprocessor', preprocessor_g),\n",
    "        ('regressor', VotingRegressor([\n",
    "            ('rf', RandomForestRegressor(n_estimators=30, max_depth=10, random_state=42)),\n",
    "            ('gb', GradientBoostingRegressor(n_estimators=50, random_state=42)),\n",
    "            ('dt', DecisionTreeRegressor(max_depth=8, random_state=42))\n",
    "        ]))\n",
    "    ])\n",
    "    \n",
    "    model_g.fit(X_train_g, y_train)\n",
    "    models.append(model_g)\n",
    "    \n",
    "    pred_g = model_g.predict(X_test_g)\n",
    "    preds_test.append(pred_g)\n",
    "\n",
    "# Combina predicciones por promedio simple\n",
    "y_pred_late = np.mean(preds_test, axis=0)\n",
    "\n",
    "print(\"Late Fusion - R²:\", r2_score(y_val, y_pred_late))\n",
    "print(\"Late Fusion - RMSE:\", mean_squared_error(y_val, y_pred_late))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4240d311",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define grupos (puedes ajustar estos grupos)\n",
    "group1 = ['assignatura', 'codi_assignatura', 'curs_academic']\n",
    "group2 = ['discapacitat', 'estudis_mare', 'estudis_pare']\n",
    "group3 = [ 'sexe', 'taxa_exit' ]\n",
    "group4 = ['nota_d_acces',  'via_acces_estudi']  \n",
    "\n",
    "feature_groups = [group1, group2, group3, group4]\n",
    "\n",
    "models = []\n",
    "preds_test = []\n",
    "\n",
    "for group in feature_groups:\n",
    "    X_train_g = X_train[group]\n",
    "    X_test_g = X_test[group]\n",
    "    \n",
    "    cat_cols_g = X_train_g.select_dtypes(include='object').columns.tolist()\n",
    "    preprocessor_g = ColumnTransformer([\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols_g)\n",
    "    ], remainder='passthrough')\n",
    "    \n",
    "    model_g = Pipeline([\n",
    "        ('preprocessor', preprocessor_g),\n",
    "        ('regressor', VotingRegressor([\n",
    "            ('rf', RandomForestRegressor(n_estimators=30, max_depth=10, random_state=42)),\n",
    "            ('gb', GradientBoostingRegressor(n_estimators=50, random_state=42)),\n",
    "            ('dt', DecisionTreeRegressor(max_depth=8, random_state=42))\n",
    "        ]))\n",
    "    ])\n",
    "    \n",
    "    model_g.fit(X_train_g, y_train)\n",
    "    models.append(model_g)\n",
    "    \n",
    "    pred_g = model_g.predict(X_test_g)\n",
    "    preds_test.append(pred_g)\n",
    "\n",
    "# Combina predicciones por promedio simple\n",
    "y_pred_late = np.mean(preds_test, axis=0)\n",
    "\n",
    "print(\"Late Fusion - R²:\", r2_score(y_val, y_pred_late))\n",
    "print(\"Late Fusion - RMSE:\", mean_squared_error(y_val, y_pred_late))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synthesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
